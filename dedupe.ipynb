{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os, errno, operator, re, sys, subprocess, signal, redis\n",
    "#sys.path.append(os.path.join(wdir, '..', 'flaubert'))\n",
    "#import flaubert.punkt\n",
    "from __future__ import division\n",
    "from IPython.core.debugger import Pdb\n",
    "import pickle\n",
    "import ast\n",
    "import random\n",
    "import numpy as np\n",
    "import enchant\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import bigrams,ConditionalFreqDist,FreqDist,pos_tag,pos_tag_sents\n",
    "from gensim import parsing, matutils, interfaces, corpora, models, similarities, summarization\n",
    "from gensim.utils import lemmatize\n",
    "from nltk import collocations, association, text, tree\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.similarities.docsim import SparseMatrixSimilarity\n",
    "from reader import Json100CorpusReader\n",
    "import itertools, shutil, requests\n",
    "from collections import Counter\n",
    "from bisect import bisect_left\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "#from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "#from sklearn.tree import DecisionTreeClassifier \n",
    "#from sklearn.learning_curve import learning_curve\n",
    "\n",
    "import re\n",
    "from lxml import etree\n",
    "from StringIO import StringIO\n",
    "from os import listdir\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import (\n",
    "    DependencyGraph, ProjectiveDependencyParser, NonprojectiveDependencyParser)\n",
    "from nltk.parse.malt import MaltParser as MaltParser\n",
    "\n",
    "from nltk.corpus import dependency_treebank as dt\n",
    "from nltk.corpus import treebank_raw\n",
    "from nltk.corpus import treebank\n",
    "from pickle import load\n",
    "from nltk.parse import stanford\n",
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "\n",
    "from glob import iglob\n",
    "from StringIO import StringIO\n",
    "from os import listdir\n",
    "from os.path import getmtime, join, realpath\n",
    "import getpass\n",
    "import dateutil.parser\n",
    "from pytz import utc\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tla = ['abo', 'sub', 'apa', 'cto']\n",
    "NAME = os.environ.get('NAME') or 'dmoz'\n",
    "wdir = os.path.expanduser('~/scrapy')\n",
    "os.environ['CLASSPATH'] = join(wdir, 'lib')\n",
    "odir = join(wdir, NAME)\n",
    "os.chdir(odir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_index_of(id, lo=0, hi=None):\n",
    "    hi = hi if hi is not None else len(sids)\n",
    "    pos = bisect_left(sids, id, lo, hi)\n",
    "    return (pos if pos != hi and sids[pos] == id else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_dict():\n",
    "    # corpora.Dictionary is a static method of gensim.corpora\n",
    "    # it establishes the base of operations numbering the vocab,\n",
    "    # and you feed it strings such as doc2bow(feedit) produces a sparse vector.\n",
    "\n",
    "    # itertools.chain(*vOfv) produces a yielder of flattened docs (vOfw)\n",
    "    # list(itertools.chain(*vOfv)) spells out the yield\n",
    "    dictionary = corpora.Dictionary(list(craigcr))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def datetime_parser(json_dict):\n",
    "    for k,v in json_dict.iteritems():\n",
    "        try:\n",
    "            json_dict[k] = dateutil.parser.parse(v)\n",
    "        except (ValueError, AttributeError):\n",
    "            pass\n",
    "    return json_dict\n",
    "def determine_seven_day_fencepost(dt1):\n",
    "    Markers = sorted([f for f in os.listdir(odir) if re.search(r'Marker\\..*\\.json$', f)], \\\n",
    "                     reverse=True)\n",
    "    jsons = []\n",
    "    for m in Markers:\n",
    "        within = False\n",
    "        with open(join(odir, m), 'r') as fp:\n",
    "            url2dt = json.load(fp, object_hook=datetime_parser)\n",
    "            for url,dt0 in url2dt.iteritems():\n",
    "                if (dt1 - dt0).days < 7:\n",
    "                    within = True\n",
    "                    break\n",
    "        if within:\n",
    "            jsons.append(\"{}.{}.json\".format(NAME, m.split('.')[1]))\n",
    "        else:\n",
    "            break\n",
    "    return jsons\n",
    "dt_marker1 = datetime.fromtimestamp(getmtime(os.path.realpath(join(odir, 'marker1'))))\n",
    "utcnow = utc.localize(dt_marker1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "jsons = determine_seven_day_fencepost(utcnow)\n",
    "craigcr = Json100CorpusReader(odir, jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "coords = list(craigcr.coords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "links = list(craigcr.field('link'))\n",
    "prices = list(craigcr.price())\n",
    "ids = list(craigcr.field('id'))\n",
    "sids = sorted(ids)\n",
    "posted = [dateutil.parser.parse(t) for t in list(craigcr.field('posted'))]\n",
    "bedrooms = []\n",
    "for i, z in enumerate(zip(craigcr.attrs_matching(r'[0-9][bB][rR]'), craigcr.field('title'), craigcr.raw())):\n",
    "    if z[0] is not None:\n",
    "        bedrooms.append(int(re.findall(r\"[0-9]\", z[0])[0]))\n",
    "    else:\n",
    "        m = re.search(r'(1|one|2|two|3|three|4|four).{0,9}(b[rd]\\b|bed)', z[1] + z[2], re.IGNORECASE)\n",
    "        if m:\n",
    "            if re.search(m.group(1), \"one\", re.IGNORECASE):\n",
    "                bedrooms.append(1)\n",
    "            elif re.search(m.group(1), \"two\", re.IGNORECASE):\n",
    "                bedrooms.append(2)\n",
    "            elif re.search(m.group(1), \"three\", re.IGNORECASE):\n",
    "                bedrooms.append(3)\n",
    "            elif re.search(m.group(1), \"four\", re.IGNORECASE):\n",
    "                bedrooms.append(4)\n",
    "            else:\n",
    "                bedrooms.append(int(m.group(1)))\n",
    "        else:\n",
    "            bedrooms.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class i2what(object):\n",
    "    def __init__(self, arr):\n",
    "        self._i2w = arr\n",
    "    def __len__(self):\n",
    "        return len(self._i2w)    \n",
    "    def q_dupe(self, i):\n",
    "        return self._i2w[i] < 0\n",
    "    def __getitem__(self, i):\n",
    "        return abs(self._i2w[i])\n",
    "    def __iter__(self):\n",
    "        for i in self._i2w:\n",
    "            if self.q_dupe(i):\n",
    "                next\n",
    "            else:\n",
    "                yield self[i]\n",
    "        \n",
    "def CorpusDedupe(cr, dict):\n",
    "    # dict.doc2bow makes:\n",
    "    #   corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
    "    #             [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
    "    #             [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],      ]\n",
    "    corpus = [dict.doc2bow(doc) for doc in list(cr)]\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "    i2text = np.arange(1,len(corpus)+1,1)\n",
    "    i2loc = np.arange(1,len(corpus)+1,1)\n",
    "    index = SparseMatrixSimilarity(tfidf[corpus], num_features=len(dict.keys()))\n",
    "    for i, z in enumerate(zip(index, coords)):\n",
    "        if i2text[i] > 0:\n",
    "            negated = -i2text[i]\n",
    "            for j, sim in enumerate(z[0][i+1:]):\n",
    "                if sim > .61:\n",
    "\t\t    i2text[i] = i2text[i+1+j] = negated\n",
    "        if i2loc[i] > 0 and None not in z[1]:\n",
    "            ci = z[1]\n",
    "            negated = -i2loc[i]\n",
    "            for j, cj in enumerate(coords[i+1:]):\n",
    "                if ci == cj:\n",
    "                    i2loc[i] = i2loc[i+1+j] = negated\n",
    "    return i2what(i2text), i2what(i2loc)\n",
    "\n",
    "#list(index)[519][np.argpartition(list(index)[519], -10)[-10:]]\n",
    "#np.argpartition(list(index)[519], -10)[-10:]\n",
    "#[' '.join(s) for s in itemgetter(*[446, 287, 468,   9, 100, 104, 426, 429, 519, 433])(list(craigcr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# corpus = collection of bow sparse vectors\n",
    "i2text, i2loc = CorpusDedupe(craigcr, make_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, asin\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6372.8 # Earth radius in kilometers\n",
    "    dLat = radians(lat2 - lat1)\n",
    "    dLon = radians(lon2 - lon1)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    "\n",
    "    a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "    c = 2*asin(sqrt(a))\n",
    " \n",
    "    return R * c\n",
    "\n",
    "def within(coords):\n",
    "    if coords[0] is None or coords[1] is None:\n",
    "\treturn False\n",
    "    if NAME == \"dmoz\":\n",
    "\treturn coords[0] < 40.796126\n",
    "    # que\n",
    "    elif NAME == \"que\":\n",
    "\tkm = haversine(40.743924, -73.912388, float(coords[0]), float(coords[1]))\n",
    "\treturn km < 4\n",
    "    # sf\n",
    "    elif NAME == \"sfc\":\n",
    "\tkm = haversine(37.779076, -122.397501, coords[0], coords[1])\n",
    "\treturn km < 1.5\n",
    "    # berkeley\n",
    "    elif NAME == \"eby\":\n",
    "\tkm = haversine(37.871454, -122.298115, coords[0], coords[1])\n",
    "\treturn km < 3\n",
    "    # milbrae\n",
    "    #    km = haversine(37.600122, -122.386914, coords[0], coords[1])\n",
    "    # daly city\n",
    "    #    km2 = haversine(37.687915, -122.472452, coords[0], coords[1]))\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def qPronouns(vOfv):\n",
    "    pronouns = re.compile(\"^(i|me|mine|our|he|she|they|their|we|my|his|her|myself|himself|herself|themselves)$\", re.IGNORECASE)\n",
    "    for w in [w for sent in vOfv for w in sent]:\n",
    "\tif pronouns.search(w):\n",
    "\t    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def nPara(raw):\n",
    "    lines = raw.split('\\n')\n",
    "    wstart = next( (i for (i,l) in enumerate(lines) if re.search(r\"\\S\", l) ), 0)\n",
    "    wend = len(lines) - next( (i for (i,l) in enumerate(reversed(lines)) if re.search(r\"\\S\", l) ), 0)\n",
    "    result = 0\n",
    "    inPara = False\n",
    "    for l in lines[wstart:wend]:\n",
    "        if re.search(r\"\\S\", l):\n",
    "            if not inPara:\n",
    "                inPara = True\n",
    "                result += 1\n",
    "        elif inPara:\n",
    "            inPara = False\n",
    "    return result\n",
    "    \n",
    "def numSents(vOfv):\n",
    "    return len(vOfv)\n",
    "\n",
    "def numRecurs(vOfv):\n",
    "    return sum([1 for v in vOfv if len(v) > 13])\n",
    "\n",
    "def numYell(vOfv):\n",
    "    return sum([1 for v in vOfv for w in v if re.search(\"[A-Z]{3}\", w) and enchant.Dict().check(w)])\n",
    "\n",
    "def numWords(vOfv):\n",
    "    return sum([len(v) for v in vOfv])\n",
    "\n",
    "def numGraphs(vOfv):\n",
    "    return sum([1 for v in vOfv for w in v if re.match(r'([^0-9a-zA-Z])\\1\\1\\1', w)])\n",
    "    \n",
    "def numNonAscii(vOfv):\n",
    "    return sum([1 for v in vOfv for w in v if any(ord(char) > 127 and ord(char) != 8226 for char in w)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "firstnames = set()\n",
    "with open(join(wdir, 'firstnames'), 'r') as f:\n",
    "    for name in f.readlines():\n",
    "        name = re.sub('\\n', '', name)\n",
    "        firstnames.add(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "listedby = []\n",
    "re_suspect = r\"deal|no fee|contact|apartments|apts|for all|llc|to view|([^a-zA-Z0-9]|x)\\1\\1|rentals|real|estate\"\n",
    "for lister in [re.split(r':\\s*', i, 1).pop() if i else None for i in craigcr.attrs_matching(r'[lL]isted')]:\n",
    "    if lister is not None and not re.search(re_suspect, lister):\n",
    "        tokens = re.split(r'[^0-9a-zA-Z-]+', lister)\n",
    "        if len(tokens) >= 2 and len(tokens) < 8:\n",
    "            for i,z in list(enumerate(tokens))[:-1]:\n",
    "                if z.lower().split('-')[0] in firstnames:\n",
    "                    lister = \"{} {}\".format(tokens[i], tokens[i+1])\n",
    "                    break\n",
    "    listedby.append(lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "oklistedby = set()\n",
    "for pair in Counter(listedby).iteritems():\n",
    "    if pair[1] == 1:\n",
    "\tif not re.search(re_suspect, pair[0], re.IGNORECASE):\n",
    "\t    oklistedby.add(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "odoms = craigcr.attrs_matching(r'[oO]dom')\n",
    "odoms = [re.split(r':\\s*', i, 1).pop() if i else None for i in odoms]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(join(odir, 'files'))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.ENOENT:\n",
    "        raise\n",
    "try:\n",
    "    os.makedirs(join(odir, 'files'))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "filtered = []\n",
    "with open(join(odir, 'digest'), 'w+') as good, open(join(odir, 'reject'), 'w+') as bad:\n",
    "    for i,z in enumerate(zip(craigcr.docs(), craigcr.raw(newlines_are_periods=True))):\n",
    "        try:\n",
    "            listing = '%s %s %s' % ((' '.join([word for sent in z[0] for word in sent][0:50]), \\\n",
    "                                    links[i], \\\n",
    "                                    re.sub(r'\\s+', ' ', listedby[i]) if listedby[i] else \"Actual Person?\"))\n",
    "        except UnicodeEncodeError:\n",
    "            print  ' '.join([word.encode('utf-8') for sent in z[0] for word in sent])\n",
    "\n",
    "        # filter in order of increasing time complexity\n",
    "        if i2text.q_dupe(i):\n",
    "            bad.write((\"dupe %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        if (utcnow - posted[i]).days >= 7:\n",
    "            bad.write((\"payfor %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        if listedby[i] is not None and listedby[i] not in oklistedby:\n",
    "            bad.write((\"listedby %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        if odoms[i] and int(odoms[i]) > 160000:\n",
    "            bad.write((\"miles %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        if not within(coords[i]):\n",
    "            bad.write((\"toofar %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        if not listedby[i] and not qPronouns(z[0]):\n",
    "            bad.write((\"pronouns %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        if re.search(r'leasebreak', z[1]):\n",
    "            bad.write((\"leasebreak %s\" % listing).encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "\n",
    "        nw=numWords(z[0])\n",
    "        ns=numSents(z[0])\n",
    "        ng=numGraphs(z[0])\n",
    "        wps=float(nw/ns) if ns else 0.0\n",
    "        nr=numRecurs(z[0])\n",
    "        np=nPara(z[1])\n",
    "        spp=float(len(z[0])/np) if np else 0.0\n",
    "        ny = numYell(z[0])\n",
    "        yr=float(ny/nw) if nw else 0.0\n",
    "        nna=numNonAscii(z[0])\n",
    "\n",
    "        if nna > 3 or spp <= 1.0 or yr > 0.1 or ny > 20 or ng > 3:\n",
    "            bad.write(listing.encode('utf-8') + '\\n\\n')\n",
    "            continue\n",
    "        good.write(listing.encode('utf-8') + '\\n\\n')\n",
    "        filtered.append(i)\n",
    "\n",
    "        tla_link = re.findall(r\"({0})/(?:[^/]+/)*?(\\d+).html\".format('|'.join(tla)), links[i])[-1]\n",
    "        with open(join(odir, \"files\", \"{}-{}\".format(tla_link[0], tla_link[1])), \"w\") as f:\n",
    "            f.write(z[1].encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "red = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "for i, z in enumerate(zip(craigcr.numbers(['price']), craigcr.field('title'))):\n",
    "    if i in filtered:\n",
    "        if z[0]['price'] is not None:\n",
    "            red.hset('item.' + ids[i], 'price', z[0]['price'])\n",
    "            red.zadd('item.index.price', z[0]['price'], ids[i])\n",
    "        red.hmset('item.' + ids[i], {'link': links[i], 'title': z[1], 'bedrooms': bedrooms[i], 'coords': coords[i], 'posted': posted[i].isoformat() })\n",
    "        red.zadd('item.index.bedrooms', bedrooms[i], ids[i])\n",
    "        if None not in coords[i]:\n",
    "            red.geoadd('item.geohash.coords', *(tuple(reversed(coords[i])) + (ids[i],)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table = ['geonameid','name','asciiname','alternatenames','latitude','longitude','featureclass','featurecode','countrycode','cc2','admin1code','admin2code','admin3code','admin4code','population','elevation','dem','timezone','modificationdate']\n",
    "\n",
    "with open(join(wdir, \"NY.tsv\"), 'r') as fp:\n",
    "    for line in fp.readlines():\n",
    "        arr = line.rstrip('\\n').split('\\t')\n",
    "        e = dict(zip(table[1:], arr[1:]))\n",
    "        for k,v in e.iteritems():\n",
    "            if arr[6] == \"P\":\n",
    "                red.hset('geoitem.' + arr[0], k, v)\n",
    "                red.zadd('geoitem.index.name', 0, \"{}:{}\".format(arr[2].lower(), arr[2]))\n",
    "                red.sadd('georitem.' + arr[2], arr[0]) \n",
    "            if arr[7] == \"PPLX\":\n",
    "                red.geoadd('pplx.geohash.coords', arr[5], arr[4], arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clientcmd = \"gradle -p {} client -Pcargs=\\\"['-file', '{}', '-outputDirectory', '{}']\\\"\".format(join(wdir, \"..\", \"CoreNLP\"), join(odir, \"files\"), join(odir, \"files\"))\n",
    "servercmd = \"gradle -p {} server\".format(join(wdir, \"..\", \"CoreNLP\"))\n",
    "if getpass.getuser() == 'dick':\n",
    "    subprocess.Popen(servercmd, shell=True, stdout=subprocess.PIPE, preexec_fn=os.setsid)\n",
    "    subprocess.Popen(clientcmd, shell=True, stdout=subprocess.PIPE)\n",
    "# os.system(\"wget localhost:9000/shutdown?key=$(cat /var/tmp/corenlp.shutdown) -O -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "dedupe.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
